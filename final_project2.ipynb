{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Project Notebook 2\n",
    "### Heather Chen\n",
    "#### 4. Topic modeling using Pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45c4cc7a7d04425c8c9f57dba506b93e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>Current session?</th></tr><tr><td>0</td><td>application_1607674079580_0001</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-172-31-72-72.ec2.internal:20888/proxy/application_1607674079580_0001/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-172-31-72-90.ec2.internal:8042/node/containerlogs/container_1607674079580_0001_01_000001/livy\">Link</a></td><td>✔</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pyspark.sql.session.SparkSession object at 0x7f031d99edd0>"
     ]
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e7aa1f78b6d436a894526191f069911",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting boto3\n",
      "  Downloading https://files.pythonhosted.org/packages/2f/f5/aeb4d65266f7712a627674bd19994cee3e1c66ff588adbc4db3fc0bbbf97/boto3-1.16.34-py2.py3-none-any.whl (129kB)\n",
      "Collecting s3transfer<0.4.0,>=0.3.0 (from boto3)\n",
      "  Downloading https://files.pythonhosted.org/packages/69/79/e6afb3d8b0b4e96cefbdc690f741d7dd24547ff1f94240c997a26fa908d3/s3transfer-0.3.3-py2.py3-none-any.whl (69kB)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.7/site-packages (from boto3)\n",
      "Collecting botocore<1.20.0,>=1.19.34 (from boto3)\n",
      "  Downloading https://files.pythonhosted.org/packages/03/ef/e35e41d6e445f472ac8f4fca8dd22726d8c6dc19ab06317164a222d13599/botocore-1.19.34-py2.py3-none-any.whl (7.0MB)\n",
      "Collecting python-dateutil<3.0.0,>=2.1 (from botocore<1.20.0,>=1.19.34->boto3)\n",
      "  Downloading https://files.pythonhosted.org/packages/d4/70/d60450c3dd48ef87586924207ae8907090de0b306af2bce5d134d78615cb/python_dateutil-2.8.1-py2.py3-none-any.whl (227kB)\n",
      "Collecting urllib3<1.27,>=1.25.4; python_version != \"3.4\" (from botocore<1.20.0,>=1.19.34->boto3)\n",
      "  Downloading https://files.pythonhosted.org/packages/f5/71/45d36a8df68f3ebb098d6861b2c017f3d094538c0fb98fa61d4dc43e69b9/urllib3-1.26.2-py2.py3-none-any.whl (136kB)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.20.0,>=1.19.34->boto3)\n",
      "Installing collected packages: python-dateutil, urllib3, botocore, s3transfer, boto3\n",
      "Successfully installed boto3-1.16.34 botocore-1.19.34 python-dateutil-2.8.1 s3transfer-0.3.3 urllib3-1.26.2"
     ]
    }
   ],
   "source": [
    "sc.install_pypi_package(\"boto3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9a56b5777794dbdbf8e0a596cb9b5fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-07 14:46:28+00:00 \t 4 MB\t gdelt_data/bq-results-0107.csv \n",
      "\n",
      "2020-12-07 14:45:53+00:00 \t 4 MB\t gdelt_data/bq-results-0108.csv \n",
      "\n",
      "2020-12-07 14:47:16+00:00 \t 9 MB\t gdelt_data/bq-results-0109.csv \n",
      "\n",
      "2020-12-07 14:46:30+00:00 \t 6 MB\t gdelt_data/bq-results-0110.csv \n",
      "\n",
      "2020-12-07 14:46:04+00:00 \t 6 MB\t gdelt_data/bq-results-0111.csv \n",
      "\n",
      "2020-12-07 14:49:53+00:00 \t 2 MB\t gdelt_data/bq-results-0112.csv \n",
      "\n",
      "2020-12-07 14:50:25+00:00 \t 7 MB\t gdelt_data/bq-results-0113.csv \n",
      "\n",
      "2020-12-07 14:50:13+00:00 \t 6 MB\t gdelt_data/bq-results-0114.csv \n",
      "\n",
      "2020-12-07 14:50:22+00:00 \t 6 MB\t gdelt_data/bq-results-0115.csv \n",
      "\n",
      "2020-12-07 14:51:03+00:00 \t 10 MB\t gdelt_data/bq-results-0116.csv \n",
      "\n",
      "2020-12-07 14:49:21+00:00 \t 20 MB\t gdelt_data/bq-results-0117.csv \n",
      "\n",
      "2020-12-07 14:50:40+00:00 \t 17 MB\t gdelt_data/bq-results-0118.csv \n",
      "\n",
      "2020-12-07 14:50:24+00:00 \t 10 MB\t gdelt_data/bq-results-0119.csv \n",
      "\n",
      "2020-12-07 14:49:22+00:00 \t 41 MB\t gdelt_data/bq-results-0120.csv \n",
      "\n",
      "2020-12-07 14:49:21+00:00 \t 99 MB\t gdelt_data/bq-results-0121.csv \n",
      "\n",
      "2020-12-07 15:48:44+00:00 \t 129 MB\t gdelt_data/bq-results-0122.csv \n",
      "\n",
      "2020-12-07 14:56:08+00:00 \t 151 MB\t gdelt_data/bq-results-0123.csv \n",
      "\n",
      "2020-12-07 14:56:08+00:00 \t 185 MB\t gdelt_data/bq-results-0124.csv \n",
      "\n",
      "2020-12-07 14:56:09+00:00 \t 148 MB\t gdelt_data/bq-results-0125.csv \n",
      "\n",
      "2020-12-07 14:56:09+00:00 \t 167 MB\t gdelt_data/bq-results-0126.csv \n",
      "\n",
      "2020-12-07 14:56:09+00:00 \t 203 MB\t gdelt_data/bq-results-0127.csv \n",
      "\n",
      "2020-12-07 15:48:44+00:00 \t 255 MB\t gdelt_data/bq-results-0128.csv \n",
      "\n",
      "2020-12-07 15:13:06+00:00 \t 296 MB\t gdelt_data/bq-results-0129.csv \n",
      "\n",
      "2020-12-07 15:13:06+00:00 \t 316 MB\t gdelt_data/bq-results-0130.csv \n",
      "\n",
      "2020-12-08 17:29:14+00:00 \t 324 MB\t gdelt_data/bq-results-0131.csv \n",
      "\n",
      "2020-12-07 15:13:06+00:00 \t 210 MB\t gdelt_data/bq-results-0201.csv \n",
      "\n",
      "2020-12-07 15:13:06+00:00 \t 225 MB\t gdelt_data/bq-results-0202.csv \n",
      "\n",
      "2020-12-07 15:13:07+00:00 \t 292 MB\t gdelt_data/bq-results-0203.csv \n",
      "\n",
      "2020-12-07 15:13:07+00:00 \t 274 MB\t gdelt_data/bq-results-0204.csv \n",
      "\n",
      "2020-12-07 15:48:44+00:00 \t 272 MB\t gdelt_data/bq-results-0205.csv \n",
      "\n",
      "2020-12-07 16:09:58+00:00 \t 254 MB\t gdelt_data/bq-results-0206.csv \n",
      "\n",
      "2020-12-07 15:48:44+00:00 \t 247 MB\t gdelt_data/bq-results-0207.csv \n",
      "\n",
      "2020-12-07 16:09:58+00:00 \t 161 MB\t gdelt_data/bq-results-0208.csv \n",
      "\n",
      "2020-12-07 16:02:50+00:00 \t 155 MB\t gdelt_data/bq-results-0209.csv \n",
      "\n",
      "2020-12-07 16:02:50+00:00 \t 210 MB\t gdelt_data/bq-results-0210.csv \n",
      "\n",
      "2020-12-07 16:09:58+00:00 \t 201 MB\t gdelt_data/bq-results-0211.csv \n",
      "\n",
      "2020-12-07 16:09:58+00:00 \t 193 MB\t gdelt_data/bq-results-0212.csv \n",
      "\n",
      "2020-12-07 16:09:58+00:00 \t 217 MB\t gdelt_data/bq-results-0213.csv \n",
      "\n",
      "2020-12-07 16:09:59+00:00 \t 177 MB\t gdelt_data/bq-results-0214.csv \n",
      "\n",
      "2020-12-07 16:09:59+00:00 \t 128 MB\t gdelt_data/bq-results-0215.csv \n",
      "\n",
      "2020-12-07 16:28:43+00:00 \t 130 MB\t gdelt_data/bq-results-0216.csv \n",
      "\n",
      "2020-12-07 16:28:43+00:00 \t 186 MB\t gdelt_data/bq-results-0217.csv \n",
      "\n",
      "2020-12-07 16:28:42+00:00 \t 209 MB\t gdelt_data/bq-results-0218.csv \n",
      "\n",
      "2020-12-07 16:28:42+00:00 \t 191 MB\t gdelt_data/bq-results-0219.csv \n",
      "\n",
      "2020-12-07 16:28:42+00:00 \t 198 MB\t gdelt_data/bq-results-0220.csv \n",
      "\n",
      "2020-12-07 16:28:43+00:00 \t 257 MB\t gdelt_data/bq-results-0221.csv \n",
      "\n",
      "2020-12-07 16:28:43+00:00 \t 155 MB\t gdelt_data/bq-results-0222.csv \n",
      "\n",
      "2020-12-07 16:28:42+00:00 \t 173 MB\t gdelt_data/bq-results-0223.csv \n",
      "\n",
      "2020-12-07 16:28:43+00:00 \t 274 MB\t gdelt_data/bq-results-0224.csv \n",
      "\n",
      "2020-12-07 16:28:43+00:00 \t 302 MB\t gdelt_data/bq-results-0225.csv \n",
      "\n",
      "2020-12-07 16:53:43+00:00 \t 333 MB\t gdelt_data/bq-results-0226.csv \n",
      "\n",
      "2020-12-07 16:53:43+00:00 \t 371 MB\t gdelt_data/bq-results-0227.csv \n",
      "\n",
      "2020-12-07 16:53:44+00:00 \t 367 MB\t gdelt_data/bq-results-0228.csv \n",
      "\n",
      "2020-12-07 16:53:43+00:00 \t 276 MB\t gdelt_data/bq-results-0229.csv \n",
      "\n",
      "2020-12-07 16:53:43+00:00 \t 255 MB\t gdelt_data/bq-results-0301.csv \n",
      "\n",
      "2020-12-07 16:53:43+00:00 \t 405 MB\t gdelt_data/bq-results-0302.csv \n",
      "\n",
      "2020-12-07 16:53:43+00:00 \t 379 MB\t gdelt_data/bq-results-0303.csv \n",
      "\n",
      "2020-12-07 17:46:22+00:00 \t 389 MB\t gdelt_data/bq-results-0304.csv \n",
      "\n",
      "2020-12-07 17:18:38+00:00 \t 422 MB\t gdelt_data/bq-results-0305.csv \n",
      "\n",
      "2020-12-07 17:46:22+00:00 \t 424 MB\t gdelt_data/bq-results-0306.csv \n",
      "\n",
      "2020-12-07 17:46:22+00:00 \t 317 MB\t gdelt_data/bq-results-0307.csv \n",
      "\n",
      "2020-12-07 17:46:22+00:00 \t 333 MB\t gdelt_data/bq-results-0308.csv \n",
      "\n",
      "2020-12-07 17:18:38+00:00 \t 539 MB\t gdelt_data/bq-results-0309.csv \n",
      "\n",
      "2020-12-07 17:18:39+00:00 \t 626 MB\t gdelt_data/bq-results-0310.csv \n",
      "\n",
      "2020-12-08 11:13:06+00:00 \t 674 MB\t gdelt_data/bq-results-0311.csv \n",
      "\n",
      "2020-12-08 11:13:06+00:00 \t 773 MB\t gdelt_data/bq-results-0312.csv \n",
      "\n",
      "2020-12-08 11:13:06+00:00 \t 807 MB\t gdelt_data/bq-results-0313.csv \n",
      "\n",
      "2020-12-08 11:13:06+00:00 \t 583 MB\t gdelt_data/bq-results-0314.csv \n",
      "\n",
      "2020-12-08 11:13:06+00:00 \t 587 MB\t gdelt_data/bq-results-0315.csv \n",
      "\n",
      "2020-12-08 12:07:45+00:00 \t 754 MB\t gdelt_data/bq-results-0316.csv \n",
      "\n",
      "2020-12-08 12:07:47+00:00 \t 852 MB\t gdelt_data/bq-results-0317.csv \n",
      "\n",
      "2020-12-08 12:07:46+00:00 \t 918 MB\t gdelt_data/bq-results-0318.csv \n",
      "\n",
      "2020-12-08 12:07:46+00:00 \t 925 MB\t gdelt_data/bq-results-0319.csv \n",
      "\n",
      "2020-12-08 12:07:47+00:00 \t 865 MB\t gdelt_data/bq-results-0320.csv \n",
      "\n",
      "2020-12-08 14:11:26+00:00 \t 682 MB\t gdelt_data/bq-results-0321.csv \n",
      "\n",
      "2020-12-08 14:11:26+00:00 \t 677 MB\t gdelt_data/bq-results-0322.csv \n",
      "\n",
      "2020-12-08 13:30:22+00:00 \t 863 MB\t gdelt_data/bq-results-0323.csv \n",
      "\n",
      "2020-12-08 13:30:22+00:00 \t 891 MB\t gdelt_data/bq-results-0324.csv \n",
      "\n",
      "2020-12-08 14:11:26+00:00 \t 901 MB\t gdelt_data/bq-results-0325.csv \n",
      "\n",
      "2020-12-08 14:11:26+00:00 \t 886 MB\t gdelt_data/bq-results-0326.csv \n",
      "\n",
      "2020-12-08 15:06:24+00:00 \t 870 MB\t gdelt_data/bq-results-0327.csv \n",
      "\n",
      "2020-12-08 15:06:24+00:00 \t 603 MB\t gdelt_data/bq-results-0328.csv \n",
      "\n",
      "2020-12-08 15:06:24+00:00 \t 625 MB\t gdelt_data/bq-results-0329.csv \n",
      "\n",
      "2020-12-08 15:45:47+00:00 \t 801 MB\t gdelt_data/bq-results-0330.csv \n",
      "\n",
      "2020-12-08 15:45:47+00:00 \t 834 MB\t gdelt_data/bq-results-0331.csv"
     ]
    }
   ],
   "source": [
    "#Get the names and sizes of these data files using Amazon boto3\n",
    "import boto3\n",
    "\n",
    "s3 = boto3.resource('s3')\n",
    "bucket = 'aws-emr-resources-787469208957-us-east-1'\n",
    "bucket_resource = s3.Bucket(bucket)\n",
    "file_sizes = []\n",
    "file_names = []\n",
    "\n",
    "for obj in bucket_resource.objects.all():\n",
    "    if 'gdelt_data' in obj.key and 'bq-results' in obj.key:\n",
    "        print(obj.last_modified,\"\\t\", round(obj.size * 1e-6), \"MB\\t\",\n",
    "              obj.key, \"\\n\")\n",
    "        file_sizes.append(obj.size * 1e-6)\n",
    "        file_names.append(obj.key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4208d15079884c238ac1a4dc926fd172",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Then read these data files to spark dataframe\n",
    "df_list = []\n",
    "for filename in file_names:\n",
    "    df = spark.read.csv('s3://aws-emr-resources-787469208957-us-east-1/' + filename, header=True)\n",
    "    df_list.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9eb6e332aa1478e8620d0655dea42c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#First divide these dataframes to January, Febuary, and March\n",
    "jan_dfs = df_list[0:25]\n",
    "feb_dfs = df_list[25:54]\n",
    "march_dfs = df_list[54:85]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9034f7aa841846d7b3cf4f9c12fc0697",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Given the large volume of our data, we only select China and the U.S to see how their focused topics change over the\n",
    "#three months\n",
    "def collect_country_data(df_list, country):\n",
    "    indx = 0\n",
    "    for df in df_list:\n",
    "        df = df.filter(df.CountryCode==country)\n",
    "        if indx == 0:\n",
    "            ori_df = df\n",
    "            indx = indx + 1\n",
    "            continue\n",
    "        else:\n",
    "            curr_df = df\n",
    "            ori_df = ori_df.union(curr_df)\n",
    "            indx = indx + 1\n",
    "    return ori_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a88520353ba54b478d00586c866fd6cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Collect data from China and from US\n",
    "CH_jan_df = collect_country_data(jan_dfs, 'CH')\n",
    "CH_feb_df = collect_country_data(feb_dfs, 'CH')\n",
    "CH_march_df = collect_country_data(march_dfs, 'CH')\n",
    "\n",
    "US_jan_df = collect_country_data(jan_dfs, 'US')\n",
    "US_feb_df = collect_country_data(feb_dfs, 'US')\n",
    "US_march_df = collect_country_data(march_dfs, 'US')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8124aceffc944f387e8842b27320d52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Do basic data cleaning jobs for these dataframes\n",
    "#(Since our text data is already lowercased, we only do basic regular expressions)\n",
    "from pyspark.sql.functions import regexp_replace\n",
    "from pyspark.ml.feature import Tokenizer\n",
    "\n",
    "def reg_clean_df(df):\n",
    "    # Remove punctuation (REGEX provided) and numbers\n",
    "    wrangled = df.withColumn('text', regexp_replace(df.ContextualText, '[_():;,.!?\\\\-]', ' '))\n",
    "    wrangled = wrangled.withColumn('text', regexp_replace(wrangled.text, '[0-9]', ' '))\n",
    "\n",
    "    # Merge multiple spaces and drop null values here\n",
    "    wrangled = wrangled.withColumn('text', regexp_replace(wrangled.text, ' +', ' '))\n",
    "    wrangled = wrangled.na.drop()\n",
    "    \n",
    "    return wrangled\n",
    "\n",
    "CH_jan_cleaned_df = reg_clean_df(CH_jan_df)\n",
    "CH_feb_cleaned_df = reg_clean_df(CH_feb_df)\n",
    "CH_mar_cleaned_df = reg_clean_df(CH_march_df)\n",
    "\n",
    "US_jan_cleaned_df = reg_clean_df(US_jan_df)\n",
    "US_feb_cleaned_df = reg_clean_df(US_feb_df)\n",
    "US_mar_cleaned_df = reg_clean_df(US_march_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb8bb802c56142e6843758effb42f61e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Define a function to do the following job before topic modeling\n",
    "from pyspark.ml.feature import Tokenizer, StopWordsRemover, IDF, CountVectorizer\n",
    "\n",
    "def pre_analysis(df):\n",
    "    tokenized_df = Tokenizer(inputCol='text', outputCol='words').transform(df)\n",
    "    tokenized_df = tokenized_df.na.drop()\n",
    "    \n",
    "    # Remove stop words.\n",
    "    removeStopwords_df = StopWordsRemover(inputCol='words', outputCol='terms').transform(tokenized_df)\n",
    "\n",
    "    tf_model = CountVectorizer(inputCol=\"terms\", outputCol=\"features\", vocabSize=40000, minDF=5).fit(removeStopwords_df)\n",
    "    vectorizer = tf_model.transform(removeStopwords_df)\n",
    "    \n",
    "    idfizer = IDF(inputCol='features', outputCol='tf_idf_features')\n",
    "    idf_model = idfizer.fit(vectorizer)\n",
    "    tfidf_result = idf_model.transform(vectorizer)\n",
    "    \n",
    "    #Return a tuple for results and td model\n",
    "    return tfidf_result, tf_model;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c883e7c4154d40878ad1ab3ad9d0912a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Do pre-analysis country by country, month by month\n",
    "CH_jan_result_df, CH_jan_tf_model = pre_analysis(CH_jan_cleaned_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c34d8657caeb442680a90a974b584a92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|     tf_idf_features|\n",
      "+--------------------+\n",
      "|(26826,[0,1,3,19,...|\n",
      "|(26826,[0,1,4,7,8...|\n",
      "|(26826,[0,1,4,7,8...|\n",
      "|(26826,[0,1,4,7,8...|\n",
      "|(26826,[0,1,2,4,8...|\n",
      "+--------------------+\n",
      "only showing top 5 rows"
     ]
    }
   ],
   "source": [
    "#Show how these tf_idf features look like\n",
    "CH_jan_result_df.select('tf_idf_features').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15bbdac9111744bfbde14318d0e9999c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "CH_feb_result_df, CH_feb_tf_model = pre_analysis(CH_feb_cleaned_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4a6f99fda844dd299963f898cdfd45c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "CH_mar_result_df, CH_mar_tf_model = pre_analysis(CH_mar_cleaned_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0c17c108a034946a54e6e9fa161dd84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "US_jan_result_df, US_jan_tf_model = pre_analysis(US_jan_cleaned_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a593af36f3894879b5f9aa9aae17a58e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "US_feb_result_df, US_feb_tf_model = pre_analysis(US_feb_cleaned_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74df5c49449843279c38b61c103f1586",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "US_mar_result_df, US_mar_tf_model = pre_analysis(US_mar_cleaned_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0a4f999fd294d93927b564541021e07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.ml.feature import IDF\n",
    "from pyspark.ml.clustering import LDA\n",
    "import pyspark.sql.functions as F\n",
    "import pyspark.sql.types as T\n",
    "\n",
    "def get_words(token_list):\n",
    "    return [vocab[token_id] for token_id in token_list]\n",
    "\n",
    "#Set the number of topics=5\n",
    "num_topics = 5\n",
    "max_iter = 10\n",
    "num_top_words = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28883bae0f2f46ff90dc0e4b0bd4550e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------------------------------------------------------------------------------+\n",
      "|topic|                                                                                  topicWords|\n",
      "+-----+--------------------------------------------------------------------------------------------+\n",
      "|    0|     [flight, citizens, said, hubei, kingdom, province, travel, health, british, government]|\n",
      "|    1|      [cities, million, travel, flights, measures, government, hubei, people, city, beijing]|\n",
      "|    2|               [cases, human, new, confirmed, market, reported, people, year, sars, chinese]|\n",
      "|    3|                [case, confirmed, man, cases, health, said, woman, united, people, hospital]|\n",
      "|    4|[hospital, airport, staff, coronavirus, international, health, new, medical, patients, sars]|\n",
      "+-----+--------------------------------------------------------------------------------------------+"
     ]
    }
   ],
   "source": [
    "#Do topic modeling and get the topic words \n",
    "#China January\n",
    "lda = LDA(k=num_topics, maxIter=max_iter, featuresCol='tf_idf_features')\n",
    "lda_model = lda.fit(CH_jan_result_df)\n",
    "    \n",
    "vocab = CH_jan_tf_model.vocabulary\n",
    "udf_to_words = F.udf(get_words, T.ArrayType(T.StringType()))\n",
    "    \n",
    "CH_jan_topics = lda_model.describeTopics(num_top_words).withColumn('topicWords', udf_to_words(F.col('termIndices')))\n",
    "CH_jan_topics.select('topic', 'topicWords').show(truncate=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc0b7d2063484f9592f2cc4d1f8fb13f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------------------------------------------------------------------------------------+\n",
      "|topic|                                                                          topicWords|\n",
      "+-----+------------------------------------------------------------------------------------+\n",
      "|    0|         [new, said, beijing, people, outbreak, health, u, ship, china, coronavirus]|\n",
      "|    1|[li, hospital, party, media, patients, january, wuhan, medical, officials, wenliang]|\n",
      "|    2|      [people, said, cities, city, cases, government, chinese, million, one, flight]|\n",
      "|    3|       [cases, two, united, u, quarantine, health, citizens, south, said, confirmed]|\n",
      "|    4| [cases, deaths, new, hubei, confirmed, province, reported, number, mainland, novel]|\n",
      "+-----+------------------------------------------------------------------------------------+"
     ]
    }
   ],
   "source": [
    "#China Febuary\n",
    "lda = LDA(k=num_topics, maxIter=max_iter, featuresCol='tf_idf_features')\n",
    "lda_model = lda.fit(CH_feb_result_df)\n",
    "    \n",
    "vocab = CH_feb_tf_model.vocabulary\n",
    "udf_to_words = F.udf(get_words, T.ArrayType(T.StringType()))\n",
    "    \n",
    "CH_feb_topics = lda_model.describeTopics(num_top_words).withColumn('topicWords', udf_to_words(F.col('termIndices')))\n",
    "CH_feb_topics.select('topic', 'topicWords').show(truncate=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a480cd582a8244daaa8b64ec1aab15fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------------------------------------------------------------------------------------+\n",
      "|topic|                                                                              topicWords|\n",
      "+-----+----------------------------------------------------------------------------------------+\n",
      "|    0|              [people, said, city, virus, cases, beijing, chinese, province, new, hotel]|\n",
      "|    1|   [city, hubei, people, province, said, restrictions, outbreak, new, lockdown, beijing]|\n",
      "|    2|[coronavirus, people, us, masks, hospital, said, quarantine, symptoms, beijing, wearing]|\n",
      "|    3|                [cases, president, chinese, new, xi, virus, trump, first, world, people]|\n",
      "|    4|    [cases, new, reported, read, hubei, imported, health, deaths, infections, confirmed]|\n",
      "+-----+----------------------------------------------------------------------------------------+"
     ]
    }
   ],
   "source": [
    "#China March\n",
    "lda = LDA(k=num_topics, maxIter=max_iter, featuresCol='tf_idf_features')\n",
    "lda_model = lda.fit(CH_mar_result_df)\n",
    "    \n",
    "vocab = CH_mar_tf_model.vocabulary\n",
    "udf_to_words = F.udf(get_words, T.ArrayType(T.StringType()))\n",
    "    \n",
    "CH_mar_topics = lda_model.describeTopics(num_top_words).withColumn('topicWords', udf_to_words(F.col('termIndices')))\n",
    "CH_mar_topics.select('topic', 'topicWords').show(truncate=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1f935fac6be489ab47124528d9e02a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---------------------------------------------------------------------------------------------+\n",
      "|topic|                                                                                   topicWords|\n",
      "+-----+---------------------------------------------------------------------------------------------+\n",
      "|    0|   [plane, base, flight, anchorage, alaska, passengers, nearby, citizens, wednesday, reserve]|\n",
      "|    1|         [flights, china, cases, airlines, coronavirus, confirmed, white, house, next, trump]|\n",
      "|    2|                 [case, states, confirmed, reported, first, u, cases, woman, health, chicago]|\n",
      "|    3|[international, airport, airports, passengers, screening, san, francisco, angeles, los, year]|\n",
      "|    4|         [county, university, patient, orange, base, department, student, health, local, cdc]|\n",
      "+-----+---------------------------------------------------------------------------------------------+"
     ]
    }
   ],
   "source": [
    "#U.S. January\n",
    "lda = LDA(k=num_topics, maxIter=max_iter, featuresCol='tf_idf_features')\n",
    "lda_model = lda.fit(US_jan_result_df)\n",
    "    \n",
    "vocab = US_jan_tf_model.vocabulary\n",
    "udf_to_words = F.udf(get_words, T.ArrayType(T.StringType()))\n",
    "    \n",
    "US_jan_topics = lda_model.describeTopics(num_top_words).withColumn('topicWords', udf_to_words(F.col('termIndices')))\n",
    "US_jan_topics.select('topic', 'topicWords').show(truncate=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a40f6c01a0d34e8e8ec59eccb445037a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------------------------------------------------------------------------------------------+\n",
      "|topic|                                                                                 topicWords|\n",
      "+-----+-------------------------------------------------------------------------------------------+\n",
      "|    0|          [house, white, trump, billion, county, president, outbreak, funding, health, new]|\n",
      "|    1|        [base, air, passengers, force, quarantine, san, travis, california, ship, evacuees]|\n",
      "|    2|        [county, trump, patient, health, officials, case, medical, cdc, school, sacramento]|\n",
      "|    3|            [county, cases, santa, woman, clara, health, officials, state, case, confirmed]|\n",
      "|    4|[boston, china, washington, president, trump, massachusetts, coronavirus, said, also, city]|\n",
      "+-----+-------------------------------------------------------------------------------------------+"
     ]
    }
   ],
   "source": [
    "#U.S. Febuary\n",
    "lda = LDA(k=num_topics, maxIter=max_iter, featuresCol='tf_idf_features')\n",
    "lda_model = lda.fit(US_feb_result_df)\n",
    "    \n",
    "vocab = US_feb_tf_model.vocabulary\n",
    "udf_to_words = F.udf(get_words, T.ArrayType(T.StringType()))\n",
    "    \n",
    "US_feb_topics = lda_model.describeTopics(num_top_words).withColumn('topicWords', udf_to_words(F.col('termIndices')))\n",
    "US_feb_topics.select('topic', 'topicWords').show(truncate=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6385fdf491c2491faaa2906a64531fae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------------------------------------------------------------------------+\n",
      "|topic|                                                                  topicWords|\n",
      "+-----+----------------------------------------------------------------------------+\n",
      "|    0|  [county, cases, confirmed, march, positive, case, covid, health, state, m]|\n",
      "|    1|[trump, house, white, president, county, package, u, economic, donald, said]|\n",
      "|    2| [county, people, health, houston, city, order, chicago, said, cases, covid]|\n",
      "|    3|     [county, cases, ship, new, san, state, washington, cruise, virus, said]|\n",
      "|    4|      [new, school, seattle, york, said, city, home, march, county, schools]|\n",
      "+-----+----------------------------------------------------------------------------+"
     ]
    }
   ],
   "source": [
    "#U.S. March\n",
    "lda = LDA(k=num_topics, maxIter=max_iter, featuresCol='tf_idf_features')\n",
    "lda_model = lda.fit(US_mar_result_df)\n",
    "    \n",
    "vocab = US_mar_tf_model.vocabulary\n",
    "udf_to_words = F.udf(get_words, T.ArrayType(T.StringType()))\n",
    "    \n",
    "US_mar_topics = lda_model.describeTopics(num_top_words).withColumn('topicWords', udf_to_words(F.col('termIndices')))\n",
    "US_mar_topics.select('topic', 'topicWords').show(truncate=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 2
   },
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
